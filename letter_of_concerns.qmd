---
title: ""
author: ""
format:
  pdf:
    number-sections: false
    toc: false
    include-in-header:
      text: |
        \usepackage{float}
        \usepackage{amsmath}
        \usepackage{graphicx}
        \usepackage[none]{hyphenat}
        % simple helpers: side-by-side pair and single figure
        \newcommand{\pairfig}[5]{%
          \begin{figure}[H]\centering
          \begin{minipage}{#4\linewidth}\includegraphics[width=\linewidth]{#1}\end{minipage}\hfill
          \begin{minipage}{#5\linewidth}\includegraphics[width=\linewidth]{#2}\end{minipage}
          \caption{#3}\end{figure}}
        \newcommand{\singlefig}[3]{%
          \begin{figure}[H]\centering
          \includegraphics[width=#3\linewidth]{#1}
          \caption{#2}\end{figure}}
fontsize: 11pt
geometry: margin=1in
csl: https://www.zotero.org/styles/american-medical-association
bibliography: references.bib
link-citations: true

---

\noindent \today

RE: Post-publication concern regarding "Longitudinal Data From the KETO-CTA Study: Plaque Predicts Plaque, ApoB Does Not" (Soto-Mota *et al.* JACC: Advances, 2025; [doi:10.1016/j.jacadv.2025.101686](https://doi.org/10.1016/j.jacadv.2025.101686))


Dear Dr. Silversides,

I am submitting a post-publication concern regarding the article cited above. An independent re-analysis identifies material issues that could mislead readers. Because the findings may inform lipid-management decisions, I request editorial assessment and correction. Specific concerns are summarized below and documented in detail in the Appendix.

**Critical issues**

- **Incorrect y-axis tick labels and IQR band** ([C1–C3](#appx-c)): Fig 1B ($\Delta$PAV) tick labels show 0–10% while data span 0–20% (twofold underestimation); Fig 1A–B IQR bands conflict with the reported sample IQR and data (lower bound of band dips below data); Fig 2E–F y-axis should be –1 to 6 (not –1 to 4). Per-tick, per-panel tick-label misalignment is inconsistent with standard plotting output.
- **Claims exceed reported models** ([C4](#appx-c4)): "No association" is asserted without reporting key models: $\Delta$TPS $\sim$ ApoB; $\Delta$TPS $\sim$ LDL\text{-}C; $\Delta$TPS $\sim$ LDL\text{-}C exposure.
- **Linear-model assumptions violated** ([C5](#appx-c5)): Change-score regressions fail $\ge 2$ diagnostics (Breusch–Pagan $P\le 0.001$; Shapiro–Wilk $P\le 0.001$) despite "assumptions...corroborated".

**Major issues**

(i) **Model strategy** ([M1](#appx-m1)): The paper relies on **unadjusted univariable change-score** models; field-standard is ANCOVA (follow-up ∼ baseline + exposure + age/sex/BP).[@vanrosendael2021; @han2020] ANCOVA avoids baseline–change artifacts and yields clearer estimates.[@vickers2001; @tu2007] Omitting age/sex/BP (available in the dataset) leaves associations likely confounded.[@lehman2009; @han2020] No reported 95% CIs for $\beta$. "Predicts" is used for association models without validated prognostic performance.[@moons2015]
(ii) **Bayes factors** ([M2](#appx-m2)): Not prespecified; uses r-scale = 0.8, described as "moderately informative" yet above package’s "ultrawide"; same r-scale applied to all models with justification only for one; no standard sensitivity analysis; treats Bayes factors as posterior probabilities. [@bayesfactor_regressionbf; @kruschke_2021; @kass_raftery_1995]

*Additional items and details are described in the Appendix.*

**Requested editorial actions**  

1. **Figure corrections**: Replot Figures 1A, 1B and 2E–2F with correct y-axes and 25th–75th percentile shading; verify all figure captions against the underlying data.
2. **Analyses & reporting**: Align claims with results (include TPS models or remove claims); make ANCOVA the primary analysis; report $\beta$, 95% CI, diagnostics; if diagnostics fail, re-specify (e.g., nonlinear terms; HC/sandwich SEs); use association language and reserve "predicts/predictor" for validated prognostic models; either remove Bayes-factor claims or document prespecification and sensitivity.
3. **Independent statistical review**: Given the scope of figure and modeling issues, I respectfully request that the journal obtain an external statistical review and, depending on the findings, issue the appropriate notice (e.g., Author Correction or stronger).

**Materials provided:** Appendix (included below); reproducibility [repository](https://github.com/SloughJE/keto-cta-audit)[@slough_keto_cta_audit_repo]

I have no conflicts of interest related to this work and am available to provide any additional information.

Sincerely,  

John Edward Slough II, MA (Statistics); MBA; MSc (ICTBM)

Independent Statistician & Data Scientist

Email: john@jsdatascience.com

\newpage

# Appendix

## Summary Table of Critical and Major Issues

\begingroup\footnotesize
| ID   | Area                         | Core issue                                                     | Severity | Ref.                          |
|------|-----------------------------|----------------------------------------------------------------|----------|-------------------------------|
| C1–C3| Figures                      | Incorrect y-axis ticks (Fig 1B, 2E–F); incorrect IQR shading (1A–B)  | Critical | [C1](#appx-c1), [C2](#appx-c2), [C3](#appx-c3) |
| C4   | Results claims               | Claims exceed reported models; $\Delta$TPS models missing     | Critical | [C4](#appx-c4)                |
| C5   | Model diagnostics            | Linear‐model assumptions violated                              | Critical | [C5](#appx-c5)                |
| M1   | Model strategy & multiplicity| Univariable $\Delta$ focus; no multiplicity; predictive wording | Major    | [M1](#appx-m1)               |
| M2   | Methods (Bayes)              | Multiple BF issues (r-scale, no sensitivity, misinterpretation)| Major    | [M2](#appx-m2)                |
| M3   | Age "mediation" analysis     | Age is a confounder; CAC downstream of exposure                | Major    | [M3](#appx-m3)                |

\endgroup

**Data provenance.** Individual-level plaque metrics used for reproductions were obtained from the Citizen Science Foundation keto-CTA repository.[@csf_ketocta] The Citizen Science Foundation also funded the study (per the article’s Funding/Disclosures). Basic checks (baseline and change statistics) match the publication.

**Reproduction materials**. All reproduced figures and analyses and are in the [keto-cta-audit](https://github.com/SloughJE/keto-cta-audit) repository with instructions in the README.


**Abbreviations**: NCPV, non-calcified plaque volume; PAV, percent atheroma volume; TPS, total plaque score; CAC, coronary artery calcium; $\Delta$ denotes change/difference (e.g., $\Delta$TPS = change in TPS from baseline to 1 year follow-up)

### Critical (C1–C5) {#appx-c}

**Summary of Figure Issues (C1-C3).**
Across Figures 1A–B and 2D–F, key elements in the publication (y-axis ranges; shaded "IQR" bands) cannot be reproduced from the data. Close inspection shows the y-axis numerals do not coincide with tick marks or gridlines, with non-uniform spacing by tick and by panel (ticks are absent in some panels), and an "IQR" band falls below the lowest observations. These per-tick, per-panel offsets are inconsistent with standard plotting output (which anchors labels to ticks), and likely introduced during figure export/annotation.

\newpage

C1 and C2 reference panels from *Figure 1 Individual Change in Plaque Volume* of the published article (p. 6); left-hand images are published panels, right-hand images are reproductions.

#### C1 — Figure 1B: y-axis ticks labeled 0–10% while data span 0–20% {#appx-c1}

\pairfig{figures/published//Figure1B.jpg}{figures/reproduced/Figure1B.png}{Left: published (axis 0–10\%). Right: reproduced (axis 0–20\%).}{0.45}{0.48}

**Issue (error).** The published panel's y-axis tick labels show 0–10% although the values span 0–20%, causing a twofold underestimation of both absolute PAV and $\Delta$PAV when read from the axis.


The reproduction uses the correct 0–20\% range. The underlying data are unchanged.

**Requested correction.** Update the Figure 1B y-axis label to **0–20\%**.

\newpage

#### C2 — Figures 1A & 1B: shaded "IQR" band incorrect; caption unclear {#appx-c2}

**Quoted Claim (paper)**

> "(A). The red line represents the median change (18.9 mm³), and the shaded area represents the IQR (9.3-47.0 mm³). (B) The red line represents the median change
(0.8%), and the shaded area represents the IQR (0.3%-1.7%)." (p. 6, Figure 1 caption)

\pairfig{figures/published//Figure1A.jpg}{figures/reproduced/Figure1A.png}{Left: published (shading is approximately anchored at zero). Right: reproduced, shading is above zero).}{0.47}{0.51}

**Note.** It is assumed that the shaded band is meant to depict the interquartile range (25th–75th percentiles) across subjects at each timepoint (baseline and 1 year), not the IQR of change, a one dimensional interval metric.

Empirical 25th–75th percentiles across subjects at each timepoint:

- **Figure 1A — NCPV:** Baseline 15.5–102.3 mm³; 1 year 25.3–163.2 mm³
- **Figure 1B — PAV:** Baseline 0.50–4.98%; 1 year 1.00–6.78%

**Issue (error).** Assuming the shaded band is meant to show the interquartile range (25th–75th percentiles) across subjects at each timepoint (baseline and 1 year), the published bands do not match the empirical quartiles from the data (values listed above). In 1A the ribbon is anchored at 0, and in 1B it stays below the lower bound of the data and 0, which contradicts the observed quartile ranges. The caption quotes the IQR of paired change (a different quantity), contributing to the mismatch. Consequently, the shaded bands are not reproducible from the authors' data under either definition.

**Requested correction.**

1. Compute Q1–Q3 across subjects at baseline and at 1 year, and plot those ranges as the shaded band(s).  
2. Revise the caption to: *"The red line shows the median paired change from baseline to 1 year. The shaded band shows the interquartile range (25th–75th percentiles) across subjects at each timepoint (baseline and 1 year)."*  
3. Regenerate the panels fully from code/data so the shaded band matches the computed quartiles.

#### C3 — Figures 2D–2F: y-axis ticks labeled –1 to 4 while data span –1 to 6 {#appx-c3}

\pairfig{figures/published//Figure2F.jpg}{figures/reproduced/Figure2F.png}{Left: published (y-axis labeled -1 to 4). Right: reproduced (axis \(-1\) to 6); OLS \(lm(y \sim x)\) line with SE band.\label{fig:c3f}}{0.47}{0.47}

**Issue (error).** Axis shown as –1 to 4; underlying data require –1 to 6.
Similar to Figure 1B, Panel 2F published panel's y-axis label is inconsistent with the plotted scale. The label indicates -1 to 4, but the range should be used is -1 to 6. The same mislabeling of y-axis ticks is visible in panels **2D** and **2E** (not shown). This can mislead readers about the plotted domain and relative spread.

**Requested correction.**  
Correct the y-axis tick labels to reflect the actual plotted range in each panel.  

*Panels 2D and 2E exhibit the same y-axis label–range mismatch; 2F is shown as the example.*

\newpage
#### C4 — Conclusions exceed support from reported models {#appx-c4}

**Quoted claims (paper):**

> "In lean metabolically healthy people on KD, neither total exposure nor changes in baseline levels of ApoB and LDL-C were associated with changes in plaque." (p. 1)

> "… no association between NCPV vs LDL-C or ApoB and **TPS** vs LDL-C or ApoB." (p. 6)

> "changes in and baseline levels of ApoB were not associated with changes in NCPV or TPS as measured by CCTA." (p. 8)

**Issue (inconsistency).**
These statements bundle multiple non-equivalent associations. Several of those models are not reported.
The audit table below maps each claim to the model it implies and whether it was reported.

**Claim → model → reported? (audit checklist):**

\begingroup\small
| Abstract/Results component | Required model (example) | Reported in paper? |
|---|---|---|
| $\Delta$-plaque vs $\Delta$LDL\text{-}C | $\Delta$NCPV $\sim$ $\Delta$LDL\text{-}C | Not reported |
| $\Delta$-plaque vs LDL\text{-}C **exposure** | $\Delta$NCPV $\sim$ LDL\text{-}C exposure | Not reported |
| $\Delta$-plaque vs LDL\text{-}C **baseline** | $\Delta$NCPV $\sim$ LDL\text{-}C baseline | Not reported |
| $\Delta$-plaque vs $\Delta$ApoB | $\Delta$NCPV $\sim$ $\Delta$ApoB | Reported |
| $\Delta$-plaque vs ApoB **exposure** | $\Delta$NCPV $\sim$ ApoB exposure | Not reported |
| $\Delta$-plaque vs ApoB **baseline** | $\Delta$NCPV $\sim$ ApoB baseline | Reported |
| **$\Delta$TPS** vs LDL\text{-}C / ApoB / exposure | $\Delta$TPS $\sim$ (LDL\text{-}C or ApoB or exposure) | **Not reported** |
\endgroup

A review of Table 3 Model Results from the study confirms these omissions: it reports selected $\Delta$NCPV regressions but includes no models with $\Delta$TPS as the outcome and no models using LDL-C baseline or ApoB exposure as independent variables. These models are also absent from the supplementary material.

\singlefig{figures/published//Table3_caption.png}{Table 3 Model Results — no $\Delta$TPS models are reported.}{0.9}

**Requested correction:** Provide fitted models (coefficients, CIs, diagnostics) for all claimed relationships, especially $\Delta$TPS vs LDL-C/ApoB/exposure, or amend the conclusions.

##### $\Delta$TPS$\sim$CAC: claimed association not reproduced

Although Table 3 shows no $\Delta$TPS outcome models, the Figure 2 caption asserts an association with baseline CAC.

**Quoted claim (paper).** 

> "(C, F) Only CAC is associated with changes in NCPV and TPS." (p. 7)

Reproducing the stated model univariable linear model does not support an association: $\Delta$TPS $\sim$ CAC$_{bl}$ gives $\beta\ = 0.0017$ (95% CI: −0.0004 to 0.0038), $P = 0.11$.
Additionally:

- $\Delta\mathrm{TPS}$ has a point mass at $0$ with small $\pm$ values (58/100 zeros).
- Excess-zero test under a rounded-Gaussian *lm*: $z=5.54$, $P_{\text{boot}}<0.001$ (analytic $P<0.001$).
- Zero probability varies with baseline CAC: test of $\Pr(\Delta\mathrm{TPS}=0 \mid \mathrm{CAC}_{\mathrm{bl}})$ via logistic LRT, $\chi^2_{(1)}=5.23$, $P=0.022$.
- A two-part (hurdle-at-zero) analysis or other re-specification is warranted.[@farewell2017]

**Requested correction:** amend the TPS claim, or provide supporting analyses with appropriate modeling (see [M1](#appx-m1)) and full reporting (model specification, coefficients with 95% CIs, and diagnostics).



#### C5 — Model assumptions: diagnostics indicate violations {#appx-c5}

**Scope.** Only plaque metrics were available to audit (CAC, NCPV, TPS, PAV; see **Data provenance**), so lipid/demographic covariates (ApoB, LDL-C, age, sex, BP) were not available. Four univariable change-score models were tested:
$\Delta$NCPV $\sim$ CAC$_{bl}$, $\Delta$NCPV $\sim$ NCPV$_{bl}$, $\Delta$NCPV $\sim$ PAV$_{bl}$, $\Delta$NCPV $\sim$ TPS$_{bl}$.

**Quoted claim (paper).** 

> "All linear model assumptions were corroborated with the R function `performance::check_model`." (p. 3)

**Issue (mis-specification).** Diagnostics on the reported $\Delta$NCPV models fail $\ge 2$ tests (e.g., Breusch–Pagan $P\le 0.001$, Shapiro–Wilk $P\le 0.001$), contradicting the manuscript’s assertion that assumptions were met.

\singlefig{figures/reproduced/LM_assumptions.png}{C5a. Objective tests for four $\Delta$NCPV models; each fails $\ge 2$ assumptions.}{1}

**Context (published letter).** A letter to the editor previously questioned model assumptions, noting median/IQR summaries (skewed distributions), clustering with no clear linear trend in scatterplots, and the absence of reported diagnostics [@lopezmoreno2025]. These concerns arose from visual inspection of the published figures.

**Results of diagnostics.** Breusch–Pagan rejected homoscedasticity in all four models ($P\le 0.001$); Shapiro–Wilk rejected residual normality in all four ($P\le 0.001$); RESET indicated misspecification for $\Delta$NCPV $\sim$ CAC$_{bl}$ ($P=0.031$) and was borderline for $\Delta$NCPV $\sim$ PAV$_{bl}$ ($P=0.050$). Each model fails at least two assumption checks. Accordingly, the blanket statement that "all assumptions were corroborated" is not supported for these models.

**Example of the cited diagnostic suite.** The output of `performance::check_model` for $\Delta$NCPV $\sim$ CAC$_{bl}$ shows nonlinearity (non-flat residual smooth), heteroskedasticity (non-constant spread over fitted values), and non-normal residuals (Q–Q tails), consistent with the tests above.

\singlefig{figures/reproduced/checkmodel_deltaNCPV_CAC.png}{C5b. \texttt{performance::check\_model(lm(}$\Delta$NCPV $\sim$ CAC$_{bl}$\texttt{))} output for the reported change-score model: clear nonlinearity, heteroskedasticity, and non-normal residuals---matching BP/SW/RESET results.}{0.87}

**Generalizability.** These checks cover plaque-only change-score regressions because of data availability. Given the similar functional form and residual structure, similar violations are plausible for other reported change-score regressions (e.g., with ApoB/LDL-C), but cannot be verified without those covariates.

**Author response (post-publication).** In a response to the previously mentioned letter to the editor regarding model assumptions, the authors stated that they reran all models using robust linear regression (`MASS::rlm`) and that estimates were "consistent" with the published results. They provided no diagnostics or output, noting that "residual plot evaluation can also be subjective."[@soto2025reply] Without diagnostics, the claimed consistency cannot be independently assessed.

**Assessment.** M-estimator robust regression (e.g., `MASS::rlm`) downweights outliers/heavy tails but does not remedy nonlinearity, heteroskedasticity, or non-normal residuals (no HC/sandwich SEs were used); it also does not supply standard p-values by default. Appropriate fixes require model specification (e.g., splines/transformations) and, where variance is non-constant, heteroskedasticity-consistent (HC/sandwich) SEs. Robust regression alone does not address the violations indicated here. [@foxweisberg2019; @venables2002]

**Requested correction.** Report assumption checks for all fitted models; where violations occur, fit appropriately specified models (e.g., baseline-adjusted follow-up (see [M1](#appx-m1)) with nonlinear terms; splines/transformations where justified; HC/sandwich SEs) rather than relying solely on robust regression, and include diagnostics with the corrected analyses.


### Major (M1–M3)

#### M1 — Model strategy, reporting, multiplicity, and claim wording {#appx-m1}

**Quoted methods.** 

> "Linear models on the primary (NCPV) and secondary outcomes were univariable" (p. 3)

> "By contrast, baseline CAC was positively associated with a change in NCPV (Figure 2C) ($\beta = 1.8$, $P < 0.001$, $R^2 = 0.33$)." (p. 4)^[Table 3 reports $\beta = 0.18$ (not $\beta = 1.8$ in this quote) for the corresponding $\Delta\mathrm{NCPV}\sim \mathrm{CAC}_{bl}$ model (a 10× difference); please reconcile (units/scaling vs typographical error).]

**Evidence.** Methods describe univariable linear models on change-scores as the primary analysis; Table 3 and accompanying text report numerous univariable regressions across outcomes/exposures. The narrative alternates between "predicts/predictor" and "associated with," with a single late "exploratory analysis" caveat in the conclusion. No baseline-adjusted follow-up models (ANCOVA) or prespecified covariate set are reported. The manuscript does not report 95% confidence intervals for any $\beta$ coefficients.

**Issue (methodological concern, inconsistency).**

- Reliance on univariable change-score models invites confounding and mathematical coupling with baseline[@tu2007; @clifton2019]; change-scores compound measurement error and reduce power. Baseline imbalance and regression-to-the-mean can inflate, attenuate, or reverse associations.[@chiolero2013]
- The approach departs from standard practice[@vanrosendael2021; @han2020] for progression analyses, where follow-up is modeled as a function of baseline and covariates (ANCOVA) to obtain clinically interpretable effects at a given starting plaque burden.
- Primary models omit adjustment for age, sex, and BP despite availability and known links to plaque progression.
- $\Delta$NCPV is screened against baseline TPS, PAV, CAC, and NCPV without prespecification, even though these predictors are deterministically related and/or highly correlated (e.g., TPV ≈ NCPV + CPV; PAV = TPV/vessel volume).[@Kishi2016; @Eskerud2021; @Manubolu2024; @Nakanishi2020] This invites mechanical "plaque-predicts-plaque" findings via shared components.
- Total R² (or p-values) from univariable models is not the relevant metric when baseline to follow-up correlation is very high. With plaque measures, $\mathrm{NCPV}_{\text{follow-up}}$ is dominated by $\mathrm{NCPV}_{\text{baseline}}$ due to test–retest reliability (especially after 1 year), so univariable models such as $\Delta\mathrm{NCPV}\sim\mathrm{ApoB}$ or $\mathrm{NCPV}_{\text{follow-up}}\sim\mathrm{ApoB}$ will show low **total** $R^2$ by construction. In our reproduction, for example,
$R^2\!\left(\Delta\mathrm{NCPV}\sim\mathrm{NCPV}_{\text{baseline}}\right)=0.49$
while
$R^2\!\left(\mathrm{NCPV}_{\text{follow-up}}\sim\mathrm{NCPV}_{\text{baseline}}\right)=0.96$.
 (this difference reflects noise amplification in change scores). Additionally the ICC for the follow-up ~ baseline model is 0.91^[The intraclass correlation coefficient (ICC) is the proportion of total variance attributable to between-participant differences. With two repeated measures per person, ICC can be estimated from a one-way ANOVA (mean squares). A high ICC (≈0.91–0.95) means baseline explains most follow-up variance.]
The relevant quantity is the **partial R²** for the exposure conditional on baseline (and prespecified covariates) in an ANCOVA model:
$$
R^2_{\text{partial}}\!\big(\text{ApoB}\mid \mathrm{NCPV}_{\text{baseline}},\text{covariates}\big)
=\frac{R^2_{\text{full}}-R^2_{\text{baseline+covariates}}}{1-R^2_{\text{baseline+covariates}}}\
$$
  Interpreting the **total** R² or signficance from a univariable model understates the contribution of ApoB beyond baseline and covariates.[@Cohen2003]
- Multiplicity is not addressed despite many tests; without a plan, familywise/type-I error is inflated and false positives are expected.
  - Table 3 has ~19 unique tests; repeating the same panel in two subgroups yields ~57 tests overall. The text references $\Delta$TPS analyses not shown, so the total is plausibly >70.
- No confidence intervals for $\beta$ coefficients are reported. With modest $n$ and change-score models (which reduce precision), the results do not rule out clinically meaningful effects; "no association" wording is not supported without CIs.
- "Predicts/predictor" implies prognostic (prediction) standards[@moons2015], e.g. multivariable specification, internal validation, calibration/discrimination, which are not presented. If claims are associational, wording should reflect association rather than prediction.

**Requested action.**

1. **Clarify analytic aim.** State consistently whether analyses are **predictive** or **associative** throughout the manuscript. Use "predicts/predictor" only for validated prognostic models; otherwise use "associated with."

2. **Declare outcomes and exposures.** Specify one primary outcome and the primary exposure(s); use other plaque metrics (TPS, PAV, CAC) as outcomes or concordance checks, not predictors of NCPV, unless prespecified, otherwise results are driven by shared construct and coupling rather than etiologic signal.

3. **If association is the aim:**
   - Prespecify a primary adjustment set (e.g. baseline value of the same outcome, age, sex as confounders).
   - Report baseline-adjusted follow-up models (ANCOVA: follow-up outcome $\sim$ baseline outcome + exposure + prespecified covariates) as the main analysis, with effect estimates and 95% CIs; move univariable $\Delta$-models to the Supplement.
   - Provide full diagnostics (linearity, residuals, influence; see [C5](#appx-c5)) and, where variance is non-constant, use heteroskedasticity-consistent (HC) standard errors.

4. **If prediction is the aim:**
   - Present a multivariable prognostic model with internal validation (bootstrap or k-fold).
   - Report calibration and discrimination; do not rely on univariable screens as evidence.

5. **Multiplicity control.** Prespecify the testing family (endpoints × predictors × subgroups) and apply a strategy (e.g., Holm or FDR); emphasize effect estimates with uncertainty over dichotomous "significance."


#### M2 — Bayes-factor analysis: extra-wide r-scale, no sensitivity, misinterpreted evidence {#appx-m2}

**Quoted claims (paper).**

> "the addition of Bayesian inference adds credence to finding that there is no association between NCPV vs LDL-C or ApoB and TPS vs LDL-C or ApoB." (p. 6)

> "Bayes factors were calculated using BayesFactor::regressionBF with default settings and an rscale value of 0.8 to contrast a moderately informative prior with a conservative distribution width" (p. 3)

> "these data suggest it is 6 to 10 times more likely that the hypothesis of no association between these variables (the null) is true as compared to the alternative." (p. 6)

**Issue (mis-specification, inconsistency)**

The paper's sole rationale for adding a Bayes-factor analysis is that it "adds credence to finding there is no association". A Bayes factor quantifies evidence relative to a specified prior and model; without prespecified or externally justified priors and a sensitivity analysis, a post-hoc BF does not provide independent confirmation of 'no association.'

- `regressionBF` used with `rscale = 0.8` and described as "moderately informative."
  - Package named defaults: $\text{medium}=\frac{\sqrt{2}}{4}\approx 0.354 \;|\; \text{wide}=0.5 \;|\; \text{ultrawide}=\frac{\sqrt{2}}{2}\approx 0.707$. 0.8 is not moderate. [@bayesfactor_regressionbf]
- The same extra-wide r-scale is applied to every model with justification for only the plaque $\sim$ ApoB model.
- No prior-sensitivity analysis (a standard recommendation for Bayes-factor reporting[@kruschke_2021]) was presented 
- No indication the BF test was prespecified.
- Interpreting a BF of 6 to 10 as "6 to 10 times more likely that the hypothesis of no association between these variables (the null) is true" conflates a Bayes factor (a likelihood ratio) with posterior probability. Such a claim requires explicit prior odds.[@kass_raftery_1995]

**Requested action**

1. Re-compute Bayes factors with default r-scales (0.354, 0.5, 0.707) and \(r = 0.8\); report all values.
2. Justify the prior for each model or adopt a standard scale.
3. Indicate whether the BF analysis (and r-scale choice) was prespecified.; if post hoc, label it exploratory and provide the rationale for adding it.
4. Revise manuscript text to avoid equating BF with the probability the null is true unless prior odds are specified.  

#### M3 — Age mediation analysis: causal language and improper adjustment {#appx-m3}

\singlefig{figures/published//Age_mediation_bp.png}{M3a. Excerpt from Table 3 from the published article showing the sequential models}{0.70}

**Quoted claim (paper)**: 

> "There was no association between LDL-C exposure while on a KD (mean 5.7 years) and NCPV or TPS (Figure 2G, Table 3). Estimated lifetime LDL-C exposure was only a significant predictor of final NCPV in the univariable analysis but lost significance when age was included as a covariate (Table 3). Both age and lifetime LDL-C exposure lost significance when baseline CAC was included in the model (Table 3)." (p. 4)

**Issue (mis-specification).**  
Age is a confounder (not caused by LDL), and baseline CAC is plausibly downstream of lifetime LDL exposure. Conditioning on CAC when asking about the total effect of lifetime LDL on NCPV blocks the LDL $\to$ CAC $\to$ NCPV pathway and yields only a direct effect; it does not constitute a mediation analysis[@richiardi2013]. No mediator model or indirect effect with CI was reported. Given that the paper’s lifetime-LDL metric embeds age (see [O2](#O2)), collinearity is expected and "loss of significance" is not evidence of no association.

**Requested action.**  
Specify the causal estimand with a DAG. If mediation is intended: fit $\text{Mediator} \sim \text{Exposure} + \text{Age}$ and $\text{Outcome} \sim \text{Exposure} + \text{Mediator} + \text{Age}$ and report indirect/direct/total effects with CIs. If the target is the total effect of lifetime LDL on NCPV, do not adjust for baseline CAC; report models with/without age (confounder), with diagnostics and collinearity checks.



\newpage

### Other — Additional analysis & reporting issues {#appx-other}

\begingroup\small
| ID | Sev. | Location | Issue (concise) | Ref. | Requested action |
|----|------|----------|-----------------|------|------------------|
| O1 | Other | Methods        | Percent change reported as **ratio of medians**, not per-participant | [O1](#O1) | Provide per-subject % change (or both) with summary + CI |
| O2 | Other | Measurements   | "Lifetime LDL-C exposure" mixes time units (days + years) | [O2](#O2) | Recalculate exposure with a single time unit |
| O3 | Other | Table 1        | Total cholesterol (301–337 mg/dL; median = **338** mg/dL) | - | Correct IQR or Median |
\endgroup


#### O1 — Percent-change metric: ratio of medians, not per-subject {#O1}

**Quote**

> "The median change in NCPV was 18.9 mm³ (IQR: 9.3-47.0 mm³) and the median change in PAV was 0.8% (IQR: 0.3%-1.7%). Compared to baseline, these represent a **43% and 50% change**, respectively." (p. 4)

**Issue (clarification)**  

The paper’s "43%" (NCPV) and "50 %" (PAV) values use a **non-standard percent-change metric**, a *ratio of medians*:

$$
\frac{\operatorname{median}(\Delta)}{\operatorname{median}(\text{baseline})}\times100\%.
$$

This definition differs from the customary per-participant percent change and can under- or over-state the typical effect (see table below).

| Outcome | Ratio-of-medians | Median % change (per subject) | Mean % change |
|:--|--:|--:|--:|
| NCPV | 43% | 49.2% | 81.4% |
| PAV  | 50% | 47.3% | 80.7% |

*(participants with baseline = 0 excluded from % change calculations)*

**Requested action**

1. Report per-subject percent change with median, IQR, and 95% CI and specify how zero or near-zero baseline values were handled when computing percent change.
2. Clarify that the published 43% and 50% are ratios of medians.


#### O2 — Exposure metric: construction and units inconsistent {#O2}

**Quoted method (paper).** 

> "LDL-C exposure on a KD was calculated by summing the products of the reported days on a KD prior to study commencement and baseline LDL-C on a KD plus the study follow-up days by their final LDL-C. Estimated **lifelong** LDL-C additionally included the product of **age** upon commencing a KD and pre-KD LDL-C." (p. 3)

$$
\mathrm{Life{-}LDL}_{\mathrm{exp}}
= \mathrm{LDL}_{\mathrm{KD\text{-}exp}}
+ Age_{\mathrm{KD\text{-}start}}\cdot \mathrm{LDL}_{\mathrm{preKD}}
$$
*Unit (as written):* dimensionally inconsistent

**Issue (clarification)**

- **Dimensional inconsistency:** the "lifetime" sum mixes **days** and **years**; these are not commensurate.
- **Scale distortion:** the pre-KD term is ~**1/365** the magnitude of the day-based terms unless age is converted; if converted to days, the term becomes a near-linear **age surrogate** times one LDL value.
- **Interpretability:** model coefficients are not in a single unit (mg·day/dL **+** mg·year/dL), hindering effect-size meaning and comparisons.

**Note.** It appears some Ketogenic Diet Exposure durations are inconsistent across the study.

- Table 1 KD duration: mean **1,642.7 days (~4.5 y)**.
- Table 3 caption: "LDL-C exposure on a ketogenic diet: mean **5.7 y**."

**Requested fix.** Confirm KD duration. Use a single time unit (e.g., convert all time to **days** and label units), report a sensitivity dropping the pre-KD term, and consider also reporting the time-weighted mean LDL:
$$
\overline{\mathrm{LDL}}=\frac{\sum_{i}\mathrm{LDL}_{i}\,\Delta t_{i}}{\sum_{i}\Delta t_{i}}
$$
alongside total duration.


\newpage

## References
